import re
from urllib.parse import urljoin, urlparse
import aiohttp
import asyncio
from colorama import Fore, Style



# Python Diagram
print(f" ___     _____  _____ ____     ____  ____     ___  ____") 
print(f"|    | / ___/ / ___/|    \  |    ||    \   /  _]|    \ ") 
print(f"|__  |(   \_ (   \_ |  _  |  |  | |  o  ) /  [_ |  D  ) ") 
print(f" __|  | \__  | \__  ||  |  | |  | |   _/ |    _]|    / ") 
print(f"/  |  | /  \ | /  \ ||  |  | |  | |  |   |   [_ |    \ ") 
print(f"\  `  | \    | \    ||  |  | |  | |  |   |     ||  .  \ ") 
print(f"\____j  \___|  \___||__|__||____||__|   |_____||__|\_|") 
                                   

# Signature
print("\nScript by Malek Althubiany")
print("=" * 100)

_regex = {
    'google_api': r'AIza[0-9A-Za-z-_]{35}',
    'firebase': r'AAAA[A-Za-z0-9_-]{7}:[A-Za-z0-9_-]{140}',
    'google_captcha': r'6L[0-9A-Za-z-_]{38}|^6[0-9a-zA-Z_-]{39}$',
    'google_oauth': r'ya29\.[0-9A-Za-z\-_]+',
    'amazon_aws_access_key_id': r'A[SK]IA[0-9A-Z]{16}',
    'amazon_mws_auth_toke': r'amzn\\.mws\\.[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}',
    'amazon_aws_url': r's3\.amazonaws.com[/]+|[a-zA-Z0-9_-]*\.s3\.amazonaws.com',
    'amazon_aws_url2': r"(" \
           r"[a-zA-Z0-9-\.\_]+\.s3\.amazonaws\.com" \
           r"|s3://[a-zA-Z0-9-\.\_]+" \
           r"|s3-[a-zA-Z0-9-\.\_\/]+" \
           r"|s3.amazonaws.com/[a-zA-Z0-9-\.\_]+" \
           r"|s3.console.aws.amazon.com/s3/buckets/[a-zA-Z0-9-\.\_]+)",
    'facebook_access_token': r'EAACEdEose0cBA[0-9A-Za-z]+',
    'authorization_basic': r'basic [a-zA-Z0-9=:_\+\/-]{5,100}',
    'authorization_bearer': r'bearer [a-zA-Z0-9_\-\.=:_\+\/]{5,100}',
    'authorization_api': r'api[key|_key|\s+]+[a-zA-Z0-9_\-]{5,100}',
    'mailgun_api_key': r'key-[0-9a-zA-Z]{32}',
    'twilio_api_key': r'SK[0-9a-fA-F]{32}',
    'twilio_account_sid': r'AC[a-zA-Z0-9_\-]{32}',
    'twilio_app_sid': r'AP[a-zA-Z0-9_\-]{32}',
    'paypal_braintree_access_token': r'access_token\$production\$[0-9a-z]{16}\$[0-9a-f]{32}',
    'square_oauth_secret': r'sq0csp-[ 0-9A-Za-z\-_]{43}|sq0[a-z]{3}-[0-9A-Za-z\-_]{22,43}',
    'square_access_token': r'sqOatp-[0-9A-Za-z\-_]{22}|EAAA[a-zA-Z0-9]{60}',
    'stripe_standard_api': r'sk_live_[0-9a-zA-Z]{24}',
    'stripe_restricted_api': r'rk_live_[0-9a-zA-Z]{24}',
    'github_access_token': r'[a-zA-Z0-9_-]*:[a-zA-Z0-9_\-]+@github\.com*',
    'rsa_private_key': r'-----BEGIN RSA PRIVATE KEY-----',
    'ssh_dsa_private_key': r'-----BEGIN DSA PRIVATE KEY-----',
    'ssh_dc_private_key': r'-----BEGIN EC PRIVATE KEY-----',
    'pgp_private_block': r'-----BEGIN PGP PRIVATE KEY BLOCK-----',
    'json_web_token': r'ey[A-Za-z0-9-_=]+\.[A-Za-z0-9-_=]+\.?[A-Za-z0-9-_.+/=]*$',
    'slack_token': r"\"api_token\":\"(xox[a-zA-Z]-[a-zA-Z0-9-]+)\"",
    'SSH_privKey': r"([-]+BEGIN [^\s]+ PRIVATE KEY[-]+[\s]*[^-]*[-]+END [^\s]+ PRIVATE KEY[-]+)",
    'Heroku API KEY': r'[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}',
    'possible_Creds': r"(?i)(" \
                    r"password\s*[`=:\"]+\s*[^\s]+|" \
                    r"password is\s*[`=:\"]*\s*[^\s]+|" \
                    r"pwd\s*[`=:\"]*\s*[^\s]+|" \
                    r"passwd\s*[`=:\"]+\s*[^\s]+)",
}

async def fetch_url(session, url):
    try:
        async with session.get(url) as response:
            return await response.text()
    except Exception as e:
        print(f"{Fore.RED}Error fetching {url}: {e}{Style.RESET_ALL}")
        return None

def validate_url(base_url, url):
    try:
        joined_url = urljoin(base_url, url)
        result = urlparse(joined_url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False

async def extract_information(url, session):
    try:
        javascript_code = await fetch_url(session, url)

        if javascript_code:
            # Extract sensitive information
            credentials = re.findall(r'(?i)(password|username|credential|login)\s*[:=]\s*[\'"]?([^\'";]+)', javascript_code)
            emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', javascript_code)

            # Organize sensitive paths with a more specific regex
            sensitive_paths = re.findall(r'(["\']?/(?:[a-zA-Z0-9-_/]+))["\']?', javascript_code)
            # Remove consecutive slashes and empty paths
            sensitive_paths = [path for path in sensitive_paths if '///' not in path and path != '/']

            # Check for sensitive secrets leaks
            sensitive_secrets = {}
            for name, regex in _regex.items():
                matches = re.findall(regex, javascript_code)
                if matches:
                    sensitive_secrets[name] = matches

            # Extract private IP addresses
            private_ips = re.findall(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', javascript_code)

            # Extract technologies used
            technologies = re.findall(r'(React|Angular|Vue|jQuery|Backbone|Ember|Svelte)\.version\s*[:=]\s*[\'"]?([^\'";]+)', javascript_code)

            # Extract all URLs and validate them
            all_urls = re.findall(r'https?://[^\s"\';]+', javascript_code)
            valid_urls = [url for url in all_urls if validate_url(url, url)]

            # Check HTTP response code
            response_code = await get_response_code(session, url)
            if response_code and response_code != 200:
                print(f"{Fore.YELLOW}Recommendation: We recommend you to check the page manually. "
                      f"There's something wrong with this page.\n"
                      f"1. Check source code\n"
                      f"2. Use other tools to bypass this page\n"
                      f"Have a Nice day!{Style.RESET_ALL}")

            # Print the extracted information
            print(f"\n{Fore.GREEN}{'=' * 120}")
            print(f"  Information for {url}  ")
            print(f"{'=' * 120}{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}Sensitive Information:")
            print(f"Credentials: {credentials}")
            print(f"Emails: {emails}")
            print(f"Sensitive Paths:")
            for path in sensitive_paths:
                print(path)
            print(f"Sensitive Secrets Leaks:")
            for name, matches in sensitive_secrets.items():
                print(f"{name}: {matches}")
            print(f"Private IP Addresses: {private_ips}")
            print(f"{Style.RESET_ALL}")

            print(f"{Fore.CYAN}Technologies Used:")
            print(f"{technologies}")
            print(f"{Style.RESET_ALL}")

            print(f"{Fore.BLUE}All URLs in JavaScript:")
            for url in all_urls:
                print(url)
            print(f"{Style.RESET_ALL}")

            print(f"{Fore.GREEN}Validated URLs:")
            for url in valid_urls:
                print(url)
            print(f"{Style.RESET_ALL}")

            # Recommendations
            print(f"{Fore.MAGENTA}Recommendations:")
            if credentials or emails or sensitive_paths or sensitive_secrets or private_ips or valid_urls:
                print("Review and secure the identified sensitive information and potential secrets leaks.")
            else:
                print("No sensitive information or potential secrets leaks identified.")
            print(f"{Style.RESET_ALL}")

    except Exception as e:
        print(f"{Fore.RED}Error processing {url}: {e}{Style.RESET_ALL}")

async def process_urls(urls):
    async with aiohttp.ClientSession() as session:
        tasks = [extract_information(url, session) for url in urls]
        await asyncio.gather(*tasks)

async def get_response_code(session, url):
    try:
        async with session.head(url) as response:
            return response.status
    except Exception as e:
        print(f"{Fore.RED}Error getting response code for {url}: {e}{Style.RESET_ALL}")
        return None

# Read JavaScript file URLs from a text file
def read_urls_from_file(file_path):
    with open(file_path, 'r') as file:
        return [line.strip() for line in file]

# Get user input for URL or file
choice = input("Choose an option:\n1. Enter a single URL\n2. Enter the path to a text file\n")

if choice == '1':
    # Get single URL from user input
    url = input("Enter the JavaScript file URL: ")
    asyncio.run(process_urls([url]))

elif choice == '2':
    # Get file path from user input
    file_path = input("Enter the path to the file containing JavaScript file URLs: ")

    # Read JavaScript file URLs from the file
    javascript_urls = read_urls_from_file(file_path)

    # Process URLs asynchronously
    asyncio.run(process_urls(javascript_urls))

else:
    print("Invalid choice. Please choose 1 or 2.")
